# For my specific example training 
torch==2.0.1
transformers==4.36.0
tokenizers==0.15.2
accelerate==0.25.0
bitsandbytes==0.41.1
peft==0.7.0
datasets==2.15.0
numpy==1.24.3
pandas
python-dotenv
scipy==1.10.1
safetensors>=0.4.0
huggingface-hub>=0.19.0
triton==2.0.0
sentencepiece
protobuf
